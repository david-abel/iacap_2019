Today we'll have talks focusing

\subsection{Fiona McEvoy on AI-Driven Behavior Change}

{\bf Goal:} recommendations for future research on {\it decision guidance} algorithms (not decision-making algorithms). \\

$\ra$ Example: google results based on clicks/habits, recommendations systems. \\

``Nudge": any aspect of a system/intervention that alters people's behavior in a predictable way without forbidding any options or significantly changing economic incentives. Think: bench with bars on it vs. a sign. \\

{\bf Two Decision-Making Systems:} System 1 (automatic/intuition), and System 2 (rational thinking). ``Nudge" is making use of System 1. \\

\ddef{Hypernudging}{A feedback loop online that contributes heavily to how individuals make decision.}

$\ra$ Data collection about decisions and actions. \\

{\bf Point:} Hypernudging has been accused of manipulation. \\

Q: Which features keep nudges consistent with autonomous human decision-making, and which force them to be manipulative? \\

Hypothesis: the more imersive an environment is, the more they can manipulate individuals. \\

\ddef{Autonomy}{Two notions: 1) the {\it opportunity} for autonomy; Mill's freedom from manipulation, and 2) capacity for autonomy; I should be able to pursue my goals.}

One group: The environment is full of non-rational influences. So, even our most rational decisions fall out of non-rational effects. Therefore, it must be permissible to shape the choice environment. \\

$\ra$ Distinction: shaping environment vs distorting! ``Shape" is \dnote{I missed it, something like ``A intends to Y, based on Z"}, vs. distort: ``A intends to do X". \\


Features of ethically-permissible nudges:
\begin{itemize}
    \item A range of options from which to choose
    \item Can make a decision that differs from the preferences of the individual.
    \item Environment is non-deceptive/distorting/subliminal.
\end{itemize}

Three case studies:
\begin{enumerate}
    \item Online (based on Karen Yeung's work on hypernudges~\cite{yeung2017hypernudge}).
    
    $\ra$ Yeung says most online systems are manipulative in the sense that people are coerced into making non-rational decisions.
    
    \item Voice Controlled IoT: Whoever controls these has immense power: company that makes these software/hardware systems gets to choose a lot of things for you (which music service you use, shopping platform, and so on).
    
    $\ra$ Relationship between IoT/voice systems and people is becoming richer and more complex. Relationships/sensitivity develops, which masks the fact that these items are commercial entities.
    
    \item Virtual/Augmented Reality: New frontier -- nudges/distortion possible by visual/3d construction of avatars, lots of opportunity to manipulate users through the environment. \\
    
    $\ra$ Example: put elementary school kids into a VR environment, and they {\it remembered} the experience (1-2 weeks later) as a real experience (not as VR?).
    
\end{enumerate}

By the nature of all three environments, there is heavy psychological potency to manipulate users. \\

Wired: ``AR will spark the next big tech platform." $\ra$ Claim: we will use AR as the next frontier.

\spacerule

\subsection{Karen Gonzalez-Fernandez on Logic
and Heuristics in Cognitive Psychology}

Logic and heuristics have a long history: heuristics tends to be linked to the process of discovery, particularly under uncertainty and economical considerations. Conversely, logic is about deduction and certainty. \\

Q: Should logic and heuristics both be considered as part of the norms of reasoning in people? \\

{\bf Goal:} Show how logic and heuristics are understood as criteria of rationality. \\

Q: What is the role of logic/heuristics in rationality in cognitive psychology?\\

Proposal 1: ``To be rational is to reason in accordance with principles of reasoning that are based on rules of logic, probability and so forth....such rules are normative principles of reasoning"~\cite{stein1996without}. \\

Proposal 2: heuristics are ``strategies that allos us to make plausible inferences econmizing cognitive resources". \\

$\ra$ Kahneman and Tversky~\cite{kahneman2013prospect}: two systems of reasoning.
\begin{enumerate}
    \item System 1: intuitive system
    \item System 2: rational system.
\end{enumerate}

$\ra$ Heuristics appear in judgments of system 1 because they are more accessible. \\

$\ra$ Heuristics produce {\bf bias} and must be studied mainly to overcome/strategize w.r.t. systematic errors we make. \\

{\bf Gigerenzer:} proposal for ecological rationality~\cite{todd2012ecological}. In ``small worlds" only classical logics an be applied. In ``large worlds", logic can't be applied, so we need heuristics.

$\ra$ Can develop either descriptive models or normative models of heuristics. \\

{\bf Proposal:} Logic vs. heuristics as a criterion of rationality. Consider the following properties:
\begin{dtable}{ll}
{\bf Logic}&{\bf Heuristics} \\
\midrule
Logical Omniscience& Lose valid inferences \\
Infallibility& Fallibility \\
Consistency& Inconsistency \\
Context-free rules& Rules influenced by context\\
No constraints& Limitations of time/memory \\
\end{dtable}

$\ra$ Takeaway: logic and heuristics are in conflict with one another. \\

$\ra$ But, from recent work in AI, perhaps we can find a more cooperative model that incorporates both strategies. Some proposals define an algorithm as logic w/ control, that unifies aspects of both approaches. \\

{\bf Conclusion:} Logic and heuristics can cooperate. Take Gillies proposal that Inference = Logic + control, we can:
\begin{enumerate}
    \item Introduce non-classical logics
    \item Find a better understanding of processes we make when we reason in ordinary life and inside scientific methodology.
    \item Open Problem (for psychologists): Why should we maintain classical logics as a paradigm for rationality? Should we include non-classical logics in our theories of rationality?
    \item Open Problem (for philosophers): What are we doing when we do logic? How should we understand the relationship between logic and reasoning?
\end{enumerate}

\spacerule



\subsection{Keynote: Alexandru Baltag on The Topology of Surprise}

Q: Knowing the world: Can I ever know the state of the world? \\

A: Well, it depends! On three things:
\begin{enumerate}
    \item The actual world: some worlds are knowable, some not.
    \item What can I observe? Topology of observable evidence.
    \item Background information: are we given any prior knowledge?
\end{enumerate}

$\ra$ Knowability of the world sounds metaphysical and unapplied. But, in a state-space formalism, the state of the world is an abstraction: the most refined description of the world that is relevant for the given purposes. \\

$\ra$ This description {\it consists of the answer to relevant questions}. \\

\dbox{Central Question: is it possible to learn the answer to some (relevant) question, given enough observable evidence.}

Consider the following paradox:

\ddef{Surprise Exam Paradox}{A student know the date of an exam is next week. Doesn't know which day. \\

Teacher announces that the exam's date will be a surprise: even in the evening before the exam, the student will not be sure that the exam is tomorrow. (also all participants can't lie).}

But, applying backwards induction: if the announcement is true, then the test cannot take place any day of the week! So, the test cannot be a surprise and the student dismisses the announcement. But then, the test will be a surprise! Paradox. \\

Note that there are multiple interpretations here: the student might not be able to eliminate Thursday (and the rest of the days, only Friday). That is:
\begin{enumerate}
    \item Non-self-referential interpretation: teacher meant ``you wouldn't know in advance the day of the exam, without any help from me (if you are not using even the information that I am announcing now).
    
    $\ra$ Thus, the elimination process stops here.
    
    \item Self-referential interpretation (most common): teacher meant ``you will not know in advance the exam day, period, even after hearing this announcement.
    
    $\ra$ But, this version leads to a paradox (a non-lying teacher can't answer the question ``after hearing this announcement, will the exam still be a surprise?" five times (``no", specifically), and avoid contradiction.
\end{enumerate}


\ddef{Topology}{A topology on a set $\mc{X}$ is given by a family $\mathbb{T} \subseteq P(\mc{X})$, or ``states": possible descriptions of the actual world.}

So: the set of possible worlds is defined by the space $\mc{X}$. \\

$\ra$ Open sets represent the agent's evidence about the world: at world $x \in \mc{X}$, every open set $\mc{U} \in \mathbb{T}$ with $x \in \mc{U}$ is a piece of evidence. \\

Two interpretations: 1) evidence in hand (topology of actual evidence), and 2) evidence out there (topology of potential evidence). \\

Q: Why a topology? \\

A: Start with properties of the world that are directly observable, they form a topological basis. \\

Typical assumptions:
\begin{itemize}
    \item CS/Econominists tend to assume that the topology given is a {\it partition} of the state space $\mc{X}$.
    
    $\ra$ Assumes absolute certainty.
    
    \item Others tend to latch onto {\it potential} evidence, which leads to making no restrictions on the topologies.
\end{itemize}

Setting: multiple agents, multiple perspectives. This requires multiple topologies. \\

Some definitions:
\begin{enumerate}
    \item Neighborhood of a point $x \in \mc{X}$ is  any open set $\mc{U}$ where $x \in \mc{U}$.
    \item Interior point of a set $\mc{A} \subset \mc{X}$ is a point $x$ such that there is a neighborhood of $x$ where $\mc{U} \subseteq \mc{A}$.
    \item A limit point of a set A is a point $x \in \mc{X}$ s.t. every neighborhood of $x$ contains a point $y \in \mc{A}$ with $y \neq x$.
    \item Interior of A is the set of all its interior points:
    \[
    Int(A) = \{x \in \mc{X} \mid \exists U \in \mathbb{T}(x \in \mc{U} \subseteq \mc{A}\}
    \]
    \item Closure of $A$ is:
    \[
    Cl(\mc{A}) = \{x \in \mc{X} \mid \forall U \in \mathbb{T}(x \in \mc{U} \ra \mc{U} \cap \mc{A} \neq \emptyset\}
    \]
    \item The (Cantor) derivative of A is the set of its limits points:
    \[
    d(\mc{A}) := \{x \in \mc{X} \mid \forall \mc{U} \in \mathbb{T}(x \in \mc{U} \ra (\mc{U} - \{x\})\cap A \neq \emptyset\}
    \]
\end{enumerate}

Note: the interior satisfies the dual axioms, corresponding to a modal system (S4):
\begin{align}
    &Int(\mc{X}) = \mc{X}, &Int(\mc{A}) \subseteq \mc{A} \\
    &Int(\mc{A} \cap \mc{B}) = Int(\mc{A}) \cap Int(\mc{B}), &Int(Int(\mc{A})) = Int(\mc{A}).
\end{align}

Epistemic interpretation: captures main properties of a natural concept of knowledge or knowability (based roughly on the modal system S4). \\


Important Distinction: 1) you know/do not know, vs. 2) you can know/cannot know. \\

Example topologies:
\begin{enumerate}
    \item Complete ignorance: the trivial topology $\mathbb{T} = \{\emptyset, \mc{X}\}$.
    \item Omniscience (god): $\mathbb{T} = P(\mc{X}) = \{\mc{Y} \mid \mc{Y} \subseteq \mc{X}\}$
    \item Knowledge based on measurements of points on a line.
\end{enumerate}

So far: we have a proper definition of knowledge and knowability. Let us return to the question: \\

Q: Is the actual state of the world known? \\

A: Depends on evidence. Suppose background information is given by a subset $\mc{A} \subseteq \mc{X}$ of a topological space. \\

$\ra$ Suppose: actual world $x$ belongs to $\mc{A}$. Then, I can know actual world $x$ iff $x$ is isolated in $A$, that is, iff $\{x\} = \mc{U} \cap \mc{A}$ for some open set $\mc{U} \in \tau_\mc{X}$.\\

{\bf Example:} Policeman and the Speeding Car.
\begin{itemize}
    \item Policeman uses a radar with accuracy $\pm$ 2 mph to determine whether the car is speeding in a 50mph zone.
    \item Radar shows 51 mph.
    \item $\mc{X} = (0, \infty)$ is the set of possible worlds where we assume the car is known to be moving.
    \item The property ``speeding" is knowable, but it is now known in this context.
\end{itemize}

{\bf Example:} Teacker marks a point $x$ on a real line $R$. Announces that the point is in the set:
\begin{align}
A = &\{0\}\ \cup OR\\
&\{\frac{1}{n} : n \in \mathbb{N}, n \geq 2\}\ OR \\ &\{\frac{1}{n} + \frac{1}{n^m} : n,m \in \mathbb{N}_{\geq 2}\}\ OR\\
&[1,2].
\end{align}

Q: Can the student know the position? Depends on further measurements, their accuracy, and so on. \\

$\ra$ We can bury a surprise exam paradox in here, too. \\

Let's revisit a topological epistemic analysis of the surprise exam paradox: what is the potential evidence in this context? \\

Under the self-referential view, we can recreate the paradox. The topological analysis gave us some justification as to {\it why} this is a paradox: the only perfect subset of $\mc{A}$ is the empty set! \\

Multi-agent example: Two numbers, one on each of two agents' foreheads. The numbers are off by one. \\

$\ra$ Ask each agent: do you know the number on your head? First time: no! Ask again: no! ask again: yes!


\spacerule
\subsection{David Fernandez-Duque on Stratified Evidence Logic}






Day two! The morning session will mostly be on AI.

\subsection{Bj{\" o}rn Lundgren on Self-driving Cars: An Ethical Overview}

Self-driving cars: discussion usually centers around ethical crashing and trolley problem. Two issues: 1) How should we crash (machine-ethics), 2) who is blameworthy (responsibility). \\

This talk: let's broaden the discussion! \\

Q: Why should we have self-driving cars? \\

A: Safety! Seems to be a necessary condition, in fact. \\

$\ra$ But, what is traffic safety? One answer: adsence of accidents. Another: absence of severe accidents! \\

Example: four way stops yield fewer accidents, but more severe accidents; roundabouts yield more, but less severe. \\

Q: How can we measure safety? \\

A: Karla and Paddock (2016) suggest we need a huge amount of data to {\it determine} whether cars are safe. \\

A: Alternatives? Simulations, proofs, verification, software alongside people (like Tesla). \\

A: Safe compared to what? Current drivers? \\

Fact: 93\% of accidents are human-caused. Out of these: 30\% speeding, 30\% intoxication, and 20\% distracted drivers. So, why not just solve those problems? \\

$\ra$ Alcolocks force drivers to be sober to turn the car on, and so on. Why not just adopt these techniques. \\

Q: But will this actually fix the problem? \\


%\subsubsection{Overview of Issues}
Safety beyond self driving cars:
\begin{enumerate}
    \item infrastructure is crucial! Do we plan for SDC or human driven cars?
    \item Plans require long time horizon: mixed traffic? only SDCs? Increase/decrezse of road vehicles?
\end{enumerate}

Other values:
\begin{itemize}
    \item How do we balance safety against other traffic values? (Like efficiency)
    \item Is there a minimal safety level? Should we get to pick a safety level (within reason)?
    \item If safey is increased by SDCs, does that effect our evaluation of a requirement for a minimal safety level?
    \item Might we ban driver's license? Ban less safe cars?
    \item Security: how do we protect against manipulation of sensors (analog hacking)?
    $\ra$ One option is data verification by other sources
    $\ra$ Might be possible with available technologies.
    Q: What about digital hacking? 
\end{itemize}

Further issues of {\it privacy and autonomy}:
\begin{itemize}
    \item Information dependency raises privacy concerns.
    \item What kind of data can we use? In car behavior of individuals?
    \item Who can use this data? Manufacturers? Government? And so on.
    \item {\it How} can this data be used? For safety? For commercial reasons?
    \item Can a user opt out? What about people not in the car?
\end{itemize}

Climate and environment:
\begin{itemize}
    \item It will be so convenient to travel we will likely travel {\it more}.
    \item Will we have more or less vehicles?
    \item Will SDCs compete with public transportation?
    \item Will SDCs be electric? Increase in demand for nickel/lithium?
\end{itemize}

Health Issues:
\begin{itemize}
    \item Walking less
    \item Loss in organ transplant donors, since many currently come from the result of traffic accidents.
\end{itemize}

Jobs and economy:
\begin{itemize}
    \item In Europe: 4.5\% of the workforce is in transportation. Huge loss of jobs.
    \item Will we be making more or less cars? Car industry is huge at the moment.
    \item Will SDCs increase efficiency of transport system, yielding potential for new services?
    \item Will the economy of transportation be more of an information economy, with companies like Google dominating?
\end{itemize}

Potential for Political and Social Resistance:
\begin{itemize}
    \item Labor resistance
    \item Economical models might change, resistance from traditional car manufacturers.
    \item Fear of new technology (3/4 americans fear using fully autonomous SDCs)
    \item Argue that we have a right to drive? A natural right?
\end{itemize}

Distribution of responsibility:
\begin{itemize}
    \item Who is responsible for achieving safety and other values (like privacy)?
    \item Who is responsible when things go wrong?
    \item Volvo and Audi declare responsibility for accidents (but not the other values).
\end{itemize}

Law enforcement:
\begin{itemize}
    \item What constitutes reasonable search?
    \item What is suitable balance between surveillance and privacy?
    \item 
\end{itemize}


\subsection{Steve T. McKinlay on Machiavellian Machines: Glitching AI}

{\bf Focus:} Algorithmic opacity and trust. \\

Main perspective in literature: do we accept the current degree of opacity, or should we expect full explainability? \\

This focus: more philosophical question about opacity. \\

$\ra$ Main idea: new definition of epistemic opacity for AI. \\

